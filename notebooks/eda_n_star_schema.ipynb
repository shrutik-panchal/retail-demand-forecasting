{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bb2d504a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Necessary Libraries\n",
    "import pandas as pd, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcb81ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data file\n",
    "DATA = Path(\"../data/global_superstore_2016.xlsx\")\n",
    "df = pd.read_excel(DATA)\n",
    "\n",
    "# normalise column names\n",
    "df.columns = [clm.strip().replace(\" \", \"_\").lower() for clm in df.columns]\n",
    "\n",
    "# Ensuring Date Time columns are in proper format\n",
    "for clm in [\"order_date\", \"ship_date\"]:\n",
    "    df[clm] = pd.to_datetime(df[clm], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[clm]).copy()\n",
    "\n",
    "# Ensuring the columns are numeric\n",
    "for clm in [\"sales\", \"quantity\", \"discount\",\"profit\", \"shipping_cost\" ]:\n",
    "    if clm in df.columns:\n",
    "        df[clm] = pd.to_numeric(df[clm], errors=\"coerce\")\n",
    "\n",
    "# Showing first five records\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc97af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "# df.info() # Summary of DataFrame information\n",
    "\n",
    "# Quick Exploratory Data Analysis and Quality Checks\n",
    "date_col = \"order_date\"\n",
    "# Checking for duplicate rows\n",
    "dupes = df.duplicated().sum()\n",
    "print(\"Exact duplicate rows:\", dupes)\n",
    "\n",
    "# Setting up directory for reports\n",
    "FIG = Path(\"../reports/figures\"); FIG.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f50fedf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily series\n",
    "daily = df.groupby(df['order_date'].dt.to_period('D')).agg(\n",
    "    quantity=('quantity','sum'),\n",
    "    sales=('sales','sum')\n",
    ").reset_index()\n",
    "daily['order_date'] = daily['order_date'].dt.to_timestamp()\n",
    "\n",
    "plt.figure(); plt.plot(daily['order_date'], daily['quantity'])\n",
    "plt.title(\"Daily Quantity (Units)\"); plt.tight_layout()\n",
    "plt.savefig(FIG/'daily_quantity.png', dpi=150); plt.close()\n",
    "\n",
    "plt.figure(); plt.plot(daily['order_date'], daily['sales'])\n",
    "plt.title(\"Daily Sales (Revenue)\"); plt.tight_layout()\n",
    "plt.savefig(FIG/'daily_sales.png', dpi=150); plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "58bfff5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category / Region summaries\n",
    "if 'category' in df.columns:\n",
    "    cat = df.groupby('category').agg(quantity=('quantity','sum')).reset_index().sort_values('quantity', ascending=False)\n",
    "    plt.figure(); plt.bar(cat['category'], cat['quantity']); plt.title(\"Quantity by Category\"); plt.tight_layout()\n",
    "    plt.savefig(FIG/'qty_by_category.png', dpi=150); plt.close()\n",
    "\n",
    "if 'region' in df.columns:\n",
    "    reg = df.groupby('region').agg(sales=('sales','sum')).reset_index().sort_values('sales', ascending=False)\n",
    "    plt.figure(); plt.bar(reg['region'], reg['sales']); plt.xticks(rotation=\"vertical\"); plt.title(\"Sales by Region\")\n",
    "    plt.subplots_adjust(bottom=0.3);  plt.gca().yaxis.set_major_formatter(mtick.StrMethodFormatter('{x:,.0f}'))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(FIG/'sales_by_region.png', dpi=150); plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1527a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up directory for Star Schema (BI & modelling)\n",
    "OUT = Path(\"../data/star_schema\"); OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Dimension - Date\n",
    "date_df = pd.DataFrame({\"date\": pd.date_range(df['order_date'].min(), df['order_date'].max(), freq='D')})\n",
    "date_df['date_key'] = date_df['date'].dt.strftime('%Y%m%d').astype(int)\n",
    "date_df['year'] = date_df['date'].dt.year\n",
    "date_df['quarter'] = date_df['date'].dt.quarter\n",
    "date_df['month'] = date_df['date'].dt.month\n",
    "date_df['month_name'] = date_df['date'].dt.strftime('%b')\n",
    "date_df['week'] = date_df['date'].dt.isocalendar().week.astype(int)\n",
    "date_df['dow'] = date_df['date'].dt.weekday + 1\n",
    "date_df['is_weekend'] = date_df['dow'].isin([6,7]).astype(int)\n",
    "date_df.to_csv(OUT/'dim_date.csv', index=False)\n",
    "\n",
    "# Dimension - Customer\n",
    "dim_customer = df[['customer_id','customer_name','segment']].drop_duplicates()\n",
    "dim_customer.to_csv(OUT/'dim_customer.csv', index=False)\n",
    "\n",
    "# Dimension - Product\n",
    "dim_product = df[['product_id','product_name','category','sub-category']].drop_duplicates()\n",
    "dim_product.to_csv(OUT/'dim_product.csv', index=False)\n",
    "\n",
    "# Dimension - Geography\n",
    "geo_cols = [clm for clm in ['country','region','state','city','postal_code'] if clm in df.columns]\n",
    "dim_geo = df[geo_cols].drop_duplicates().copy()\n",
    "dim_geo['geo_id'] = range(1, len(dim_geo)+1)\n",
    "dim_geo.to_csv(OUT/'dim_geo.csv', index=False)\n",
    "\n",
    "# Dimension - Fact Sales\n",
    "txn_col = 'order_id' if 'order_id' in df.columns else 'txn_id'\n",
    "if txn_col not in df.columns: \n",
    "    df[txn_col] = range(1, len(df)+1)\n",
    "\n",
    "fact_cols = [clm for clm in [txn_col, 'order_date','sales','quantity','profit','discount','product_id','customer_id','region','state','city'] if clm in df.columns]\n",
    "fact = df[fact_cols].copy()\n",
    "fact['date_key'] = fact['order_date'].dt.strftime('%Y%m%d').astype(int)\n",
    "fact = fact.merge(dim_geo, on=[clm for clm in ['region','state','city'] if clm in fact.columns], how='left')\n",
    "fact.to_csv(OUT/'fact_sales.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
